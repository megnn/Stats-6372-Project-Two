install.packages("repr")
bank_20 = read.csv("bank-additional-full.csv", sep=";")
library(dplyr)
library(ggplot2)
library(tidyr)
library(SDMTools)
library(readr)
library(digest)
library(ISLR)
library(car)
library(leaps)
library( Matrix)
library(foreach)
library(glmnet)
library(gridExtra)
library(lsmeans)
library(limma)
library(Sleuth3)
library(tseries)
library(forecast)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(epitools)
library(samplesizeCMH)
library(caret)
library(GGally)
library(glmnet)
library(bestglm)
library(data.table)
library(broom)
library(plyr)
library(repr)
library(ResourceSelection)
library(ROCR)
library(pROC)
bank_20 = read.csv("bank-additional-full.csv", sep=";")
bank_20 = read.csv("data/bank-additional-full.csv", sep=";")
bank_20 = read.csv("data/bank/bank-additional-full.csv", sep=";")
bank_20 = read.csv("data/bank-additional/bank-additional-full.csv", sep=";")
head(bank_20)
temp = bank_20 %>% filter(pdays != 999)
dim(temp)
hist(temp$pdays)
clean_bank_20<-bank_20
yes_indices = which(clean_bank_20$y == "yes")
yes_indices
yes_train_indices = sample(yes_indices, length(yes_indices) * .9)
yes_train_indices
no_indices = which(clean_bank_20$y == "no")
no_train_indices = sample(no_indices, length(yes_indices))
train_indices = c(no_train_indices,yes_train_indices)
no_indices
no_train_indices = sample(no_indices, length(yes_indices))
train_indices = c(no_train_indices,yes_train_indices)
balanced_train_bank_20 = clean_bank_20[train_indices,]
balanced_train_bank_20<-balanced_train_bank_20
head(balanced_train_bank_20)
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20<-test_bank_20
head(test_bank_20)
summary(test_bank_20)
summary(balanced_train_bank_20)
summary(bank_20)
library(dplyr)
library(plotly)
library(leaps)
library(MASS)
library(caret)
library(olsrr)
library(car)
setwd("~/datascience/DS6372/ProjectDetails")
reviews<-read.csv("beer_reviews.csv")
names(reviews)
regData <- reviews %>% filter(!is.na(beer_abv)) %>% group_by(brewery_name,beer_name) %>% summarise(all = mean(review_overall),aroma = mean(review_aroma), appearance = mean(review_appearance), palate = mean(review_palate),abv = mean(beer_abv), taste = mean(review_taste),count = n())
names(regData)
regData %>% arrange(-count)
#regData <- regData %>% dplyr::select("beer_name",all, aroma, appearance, palate, abv, taste, count)
reg <- head(regData,5000)  # This was 5000 data used for student version of SAS because it is only the limit.
pairs(regData[3:9]) # this is to compare all the points including count(no of reviews per beer)
hist(regData$count)
# we can eliminate count from the pairs and also from SAS output
# Cross Validation 75 train and 25 test..
#splitPerc = 0.75
# Set seed for reproducibility
set.seed(124)
#trainIndices = sample(1:dim(regData)[1],round(splitPerc * dim(regData)[1]))
#train = regData[trainIndices,]
#test = regData[-trainIndices,]
model7 = lm(all ~ aroma + appearance + palate + abv + taste, data = regData)
summary(model7)
k <- ols_step_both_aic(model7)
plot(k)
full.model <- lm(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData)
## All possible regression model and the values they provide.
all <- ols_step_all_possible(full.model)
View(all)
plot(all) #This displays all the attributes of the all data into a plot showing which ones are the better values.
# Best suset of regression model
subset <- ols_step_best_subset(full.model)
View(subset) # This shows all the best model based on the values of a given parameter
plot(subset)  # This displays all the parameters on a plot
# AIC forward
forw <- ols_step_forward_aic(full.model)
plot(forw)
#AIC backward
bac <- ols_step_backward_aic(full.model)
plot(bac)
#AIC both
k <- ols_step_both_aic(full.model)
plot(k)
# Stepwise regression model for AIC
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)    # The stars in the parenthesis means that it is involved in the model.
# forward regression model for AIC
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
# Backward regression model For AIC
step.model <- stepAIC(full.model, direction = "backward",
trace = FALSE)
summary(step.model)
model1 = lm(all ~ aroma + appearance + palate + abv + taste + abv*palate + abv*taste + taste*palate, data = regData)
confint(model1)
# Model selection using regsusets. We can use below to support the subset of the earlier model
# selection using stepwise
models <- regsubsets(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData, nvmax = 8,
method = "seqrep")
summary(models)
# Model Selection using forward
models <- regsubsets(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData, nvmax = 8,
method = "forward")
summary(models)
# Model Selection using Backward
models <- regsubsets(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData, nvmax = 8,
method = "backward")
summary(models)
# Model selection using K-fold cross validation and train() of the caret package
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model using backward
step.model <- train(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData,
method = "leapBackward",
tuneGrid = data.frame(nvmax = 1:8),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
# Train the model using forward
step.model <- train(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData,
method = "leapForward",
tuneGrid = data.frame(nvmax = 1:8),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
# Train the model using stepwise
step.model <- train(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData,
method = "leapSeq",
tuneGrid = data.frame(nvmax = 1:8),
trControl = train.control
)
step.model$results
step.model$bestTune
summary(step.model$finalModel)
# As you can see each and every model selection gave us different models look at those and let me know what you think. I think either one of 5,7,8 is good.
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
coef(full.model)
full.model
k <- ols_step_both_aic(full.model)
anova(full.model)
step.model1 <- stepAIC(full.model)
step.model <- full.model %>% stepAIC(trace = FALSE)
step.model1
step.model
step.model$results
step.model$rank
step.model$aic
probabilities <- full.model %>% predict(test_bank_20, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "yes", "no")
library(dplyr)
library(ggplot2)
library(tidyr)
library(SDMTools)
library(readr)
library(digest)
library(ISLR)
library(car)
library(leaps)
library( Matrix)
library(foreach)
library(glmnet)
library(gridExtra)
library(lsmeans)
library(limma)
library(Sleuth3)
library(tseries)
library(forecast)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(epitools)
library(samplesizeCMH)
library(caret)
library(GGally)
library(glmnet)
library(bestglm)
library(data.table)
library(broom)
library(plyr)
library(repr)
library(ResourceSelection)
library(ROCR)
library(pROC)
install.packages(limma)
install.packages('limma')
# Make predictions
probabilities <- full.model %>% predict(test_bank_20, type = "response")
balanced_train_bank_20 = clean_bank_20[train_indices,]
balanced_train_bank_20<-balanced_train_bank_20
summary(balanced_train_bank_20)
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20<-test_bank_20
summary(test_bank_20)
# Make predictions
probabilities <- full.model %>% predict(test_bank_20, type = "response")
predict = predict(full.model, test_bank_20)
predict = predict(full.model, test_bank_20, type = "response")
probabilities <- full.model %>% predict(test_bank_20, type = "response")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
coef(full.model)
step.model <- full.model %>% stepAIC(trace = FALSE)
coef(step.model)
# Make predictions
probabilities <- full.model %>% predict(test_bank_20, type = "response")
predict = predict(full.model, test_bank_20)
balanced_train_bank_20
summary(test_bank_20)
test_bank_20$y <- ifelse(test_bank_20$y == 'No', 0, 1)
test_bank_20
summary(test_bank_20)
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20$y
test_bank_20$y <- ifelse(test_bank_20$y == 'No', 0, 1)
test_bank_20$y
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20$y <- if(test_bank_20$y == 'No'){test_bank_20$y = 0}else{test_bank_20$y=1}
test_bank_20$y
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20$y
test_bank_20$y <- ifelse(test_bank_20$y == 'no', 0, 1)
test_bank_20$y
probabilities <- full.model %>% predict(test_bank_20, type = "response")
probabilities <- full.model %>% predict(test_bank_20)
predict = predict(full.model, test_bank_20)
predict = predict(full.model, test_bank_20$y)
test_bank_20
test_bank_20[1-20]
test_bank_20[1-19]
test_bank_20[1:19,]
test_bank_20[,1:19]
predict = predict(full.model, test_bank_20[,1:19])
test_bank_20
test_bank_20[,1:19]
test_bank_20[,1:20]
predict = predict(full.model, test_bank_20[,1:20])
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20$y <- as.factor(test_bank_20$y)
predict = predict(full.model, test_bank_20[,1:20])
probabilities <- full.model %>% predict(test_bank_20, type = "response")
predict = predict(step.model, test_bank_20[,1:20])
predict = predict(step.model, test_bank_20)#[,1:20])
probabilities <- full.model %>% predict(test_bank_20, type = "response", se.fit=FALSE)
str(test_bank_20)
test_bank_20 = clean_bank_20[-train_indices,]
str(test_bank_20)
test_bank_20$y <- as.character(test_bank_20$y)
str(test_bank_20)
probabilities <- full.model %>% predict(test_bank_20, type = "response", se.fit=FALSE)
str(balanced_train_bank_20)
balanced_train_bank_20$y <- as.character(balanced_train_bank_20$y)
##############################################################################################################
# Stepwise selection
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
test_bank_20$y <- as.factor(test_bank_20$y)
balanced_train_bank_20$y <- as.factor(balanced_train_bank_20$y)
##############################################################################################################
# Stepwise selection
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
predict = predict(full.model, test_bank_20)#[,1:20])
model <- naiveBayes(y~.,data = balanced_train_bank_20)
library(readr)
library(dplyr)
library(class)
library(caret)
library(e1071)
library(plotly)
library(tidyverse)
library(tidyr)
library(plyr)
library(klaR)
probabilities <- full.model %>% predict(test_bank_20, type = "response", se.fit=FALSE)
model <- naiveBayes(y~.,data = balanced_train_bank_20)
predict = predict(model, test_bank_20)#[,1:20])
##############################################################################################################
# Stepwise selection
full.model <- glm(y ~., data = balanced_train_bank_20)
##############################################################################################################
# Stepwise selection
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
# Stepwise regression model for AIC
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)    # The stars in the parenthesis means that it is involved in the model.
# forward regression model for AIC
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
summary(step.model)
summary(step.model) #Forward selection
step.model
stepAIC(full.model, direction = "both",
trace = FALSE)
stepAIC(full.model, direction = "forward",
trace = FALSE)
# Backward regression model For AIC
step.model <- stepAIC(full.model, direction = "backward",
trace = FALSE)
summary(step.model) #backward selection
# Model selection using regsusets. We can use below to support the subset of the earlier model
# selection using stepwise
models <- regsubsets(y ~., data = balanced_train_bank_20, family = binomial, nvmax = 8,
method = "seqrep")
# Model selection using regsusets. We can use below to support the subset of the earlier model
# selection using stepwise
models <- regsubsets(y ~., data = balanced_train_bank_20, nvmax = 8,
method = "seqrep")
summary(models)
# Model Selection using forward
models <- regsubsets(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData, nvmax = 12,
method = "forward")
summary(models)
# Model selection using regsusets. We can use below to support the subset of the earlier model
# selection using stepwise
models <- regsubsets(y ~., data = balanced_train_bank_20, nvmax = 12,
method = "seqrep")
summary(models)
# Stepwise regression model for AIC
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
vif(step.model) # vif for stepwise
# forward regression model for AIC
step.model <- stepAIC(full.model, direction = "forward",
trace = FALSE)
vif(step.model) # vif for forward
alias(step.model)
# Backward regression model For AIC
step.model <- stepAIC(full.model, direction = "backward",
trace = FALSE)
vif(step.model) # vif for backward
logr<-glm(y ~ job + education + default + contact +duration + poutcome + pdays + campaign, family = binomial(link = "logit"),data = balanced_train_bank_20)
logr.probs<-predict(logr, newdata=test_bank_20)
