---
title: "Project_2"
author: "Fabio_Savorgnan"
date: "3/14/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)
```


```{r }
library(dplyr)
library(ggplot2)
library(tidyr)
library(SDMTools)
library(readr)
library(digest)
library(ISLR)
library(car) 
library(leaps)
library( Matrix)
library(foreach)
library(glmnet)
library(gridExtra)
library(lsmeans)
library(limma)
library(Sleuth3)
library(tseries)
library(forecast)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(epitools)
library(samplesizeCMH)
library(caret)
library(GGally)
library(glmnet)
library(bestglm)
library(data.table)
library(broom)
library(plyr)
library(repr)
library(ResourceSelection)
library(ROCR)
```

# Loading the data
```{r }
bank_20 = read.csv("bank-additional-full.csv", sep=";")
head(bank_20)
bankadit<- read.csv("bank-additional.csv", sep=";")
bank_17<-read.csv2("bank-full.csv", sep=";")
bank<-read.csv2("bank.csv", sep=";")
```


```{r }
summary(bank_20)
```


# Does not look like any NAs in either data set
```{r }
#Does not look like any NAs in either data set
sapply(bank_20, function(x) sum(is.na(x)))
sapply(bank_17, function(x) sum(is.na(x)))
```

#pdays- about 40k of the 41k are at level 999, no previous contact 
#could bin this data 
```{r }
hist(bank_20$pdays)
temp = bank_20 %>% filter(pdays != 999)
dim(temp)
hist(temp$pdays)
```

# Reshape for a balance data
```{r }
yes_answer = bank_20 %>% filter(y == "yes")

no_answer_all = bank_20 %>% filter(y == "no")
no_indices = sample(dim(no_answer_all)[1], dim(yes_answer)[1])
no_answer = no_answer_all[no_indices,]

balanced_bank_20 = rbind(yes_answer, no_answer)

balanced_indices = sample(dim(balanced_bank_20)[1], round(dim(balanced_bank_20)[1] * .1 ))
balanced_test = balanced_bank_20[balanced_indices,]
balanced_test
balanced_train = balanced_bank_20[-balanced_indices,]
balanced_train

```

# Plot EDA in general for continuous variables
```{r }
plot(as.factor(bank_20$y), bank_20$age,xlab="Loan",ylab="Age",title="Credict Assessment")

p1= bank_20 %>% ggplot(aes(x = duration,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Duration", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p4= p3 + scale_x_continuous(limits = c(0, 2500))
p4

plot(campaign~y  ,data=bank_20, main="Credict Assessment",
   xlab="Campaign", ylab="Loan",col=c(1,56))

plot(previous~y  ,data=bank_20, main="Credict Assessment",
   xlab="Previous", ylab="Loan",col=c(1,56))

p1= bank_20 %>% ggplot(aes(x = emp.var.rate,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Emp Var Rate", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p4= p3 + scale_x_continuous(limits = c(-3.5, 1.4))
p4
p1= bank_20 %>% ggplot(aes(x = cons.price.idx,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Cons Price Idx", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

p1= bank_20 %>% ggplot(aes(x = cons.conf.idx,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Cons Conf", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

plot(euribor3m~y,data=bank_20, main="Credict Assessment",
   xlab="Loan", ylab="euribor3m")

p1= bank_20 %>% ggplot(aes(x = nr.employed,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Nr Employed", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

```
# EDA for categorical values with proportion table

```{r }
attach(bank_20)
ftable(addmargins(table(bank_20$y,bank_20$job))) 
job=factor(job)
ftable(addmargins(table(y, marital)))
marital=factor(marital)
ftable(addmargins(table(y,education)))
education=factor(education)
ftable(addmargins(table(y,default)))
education=factor(default)
ftable(addmargins(table(y,housing))) 
job=factor(housing)
ftable(addmargins(table(y, loan)))
marital=factor(loan)
ftable(addmargins(table(y,contact)))
education=factor(contact)
ftable(addmargins(table(y,month)))
education=factor(month)
ftable(addmargins(table(y,day_of_week)))
education=factor(day_of_week)
ftable(addmargins(table(y,poutcome)))
education=factor(poutcome)

#to get proportions that make sense
prop.table(table(bank_20$y,bank_20$job),2)
prop.table(table(y,education),2)
prop.table(table(y,default),2)
prop.table(table(y,housing),2)
prop.table(table(y,loan),2)
prop.table(table(y,contact),2)
prop.table(table(y,month),2)
prop.table(table(y,day_of_week),2)
prop.table(table(y,poutcome),2)

#Visualize
p1= bank_20 %>% ggplot(aes(x = job,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Job", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = education,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Education", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = default,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Default", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = marital,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Marital", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = housing,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Housing", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = loan,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Loan", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = contact,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Contact", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = month,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Month", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = day_of_week,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Day of week", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = poutcome,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Poutcome", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
```


```{r }

```



#PCA for continuous variables
```{r }
pc.bc<-prcomp(bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)],scale.=TRUE)
pc.bc.scores<-pc.bc$x
#Adding the response column to the PC's data frame
pc.bc.scores<-data.frame(pc.bc.scores)
pc.bc.scores$loan<-bank_20$y

#Use ggplot2 to plot the first few pc's
library(ggplot2)
ggplot(data = pc.bc.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col= loan), size=1)+
  ggtitle("PCA of Credict Assessment")
```

# Heat map for continuous variables
```{r }
my.cor<-cor(bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)])
my.cor
library(gplots)
library(ggplot2)
heatmap.2(my.cor,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("row"), 
          symm=F,symkey=T,symbreaks=T, scale="none")
```


# Pair correlation numerical variables
```{r }
# Prepare some data
df <- bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
# Correlation plot
ggcorr(df, palette = "RdBu", label = TRUE)
```


# Running LDA
```{r }
# Build X_train, y_train, X_test, y_test
X_train <- balanced_train[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_train<-balanced_train[,21]

X_test <- balanced_test[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_test <- balanced_test[,21]
mylda<-lda(y ~ age + duration + campaign+pdays + previous + emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed, data= balanced_train)
pred<-predict(mylda,newdata=X_test )$class  
Truth<-y_test
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/114
ME
#Calculating overall accuracy
oneminusME<-1-ME
oneminusME
```

# Selection of the variable for LLR 

# Forward

```{r }
model.main<- glm(y~ ., data=balanced_train,family = binomial(link="logit"))
model.null<-glm(y ~ 1, data=balanced_train,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.main),
     direction="forward",
     test="Chisq",
     data=balanced_train)
```


# The forward selection select a lot of variables. Please see below.
```{r }
forward<- glm(formula = y ~ duration + nr.employed + month + poutcome + 
    emp.var.rate + cons.price.idx + job + euribor3m + contact + 
    day_of_week + pdays + default + previous, family = binomial(link = "logit"), 
    data = balanced_train)
forward
```


# Forward Odd ratio
```{r }
summary(forward)
exp(cbind("Odds ratio" = coef(forward), confint.default(forward, level = 0.95)))
vif(forward)
```

# Take off the high VIF variances 
```{r }
forward2<- glm(formula = y ~ duration + job + contact + day_of_week + pdays + default + previous, family = binomial(link = "logit"), data = balanced_train)
forward2
```


# Plot forward

```{r }
plot(forward2)
```


# Summary model forward

```{r }
summary(forward2)
```

# Prediction with the forward selection

```{r }
logr<-glm(y ~ duration + job + contact + day_of_week + pdays + default + previous,data=balanced_train, family=binomial)

# 1 way
logr.probs<-predict(logr, newdata=balanced_test)
logr.pred<-rep("No",928)
logr.pred[logr.probs>.5]="Yes"
Truth<-balanced_test[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=balanced_test)
accuracy <- table(pred, balanced_test[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```

# Holmes test for forward selecttion
```{r }
hoslem.test(forward$y, fitted(forward), g=10)

```

# ROC curve for the forward model

```{r }
logr<-glm(y ~ duration + job + contact + day_of_week + pdays + default + previous,data=balanced_train, family=binomial)
logr.probs<-predict(logr, newdata=balanced_test)
ME<-c()
FP<-c()
FN<-c()
index<-0:928/928
for (i in 1:928){
logr.pred<-rep("no",928)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-balanced_test[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME[i]<-(x[1,2]+x[2,1])/sum(x)
FP[i]<-x[2,1]/(x[2,1]+x[1,1])
FN[i]<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
ord.ind<-order(FP,decreasing=F)
plot(FP[ord.ind],TP[ord.ind],type="l",col="blue",ylab="True Positive Rate",xlab="False Positive Rate")
lines(0.60:0.75,0.08:0.16,lty=4,col="black",lwd=1)

simple_auc <- function(TPR, FPR){
  # inputs already sorted, best scores first 
  dFPR <- c(diff(FPR), 0)
  dTPR <- c(diff(TPR), 0)
  sum(TPR * dFPR) + sum(dTPR * dFPR)/2
}

paste("AUC=", simple_auc(TP[ord.ind],FP[ord.ind]),sep=" ")

```
# Stepwise selection 
```{r }
full.model <- glm(y ~., data = balanced_train, family = binomial)
coef(full.model)
step.model <- full.model %>% stepAIC(trace = FALSE)
coef(step.model)
# Make predictions
probabilities <- full.model %>% predict(balanced_test, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "yes", "no")
# Prediction accuracy
observed.classes <- balanced_test$y
mean(predicted.classes == observed.classes)
# Make predictions
probabilities <- predict(step.model, balanced_test, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "yes", "no")
# Prediction accuracy
observed.classes <- balanced_test$y
mean(predicted.classes == observed.classes)

```


```{r }
summary(step.model)
```

```{r }
plot(step.model)
```


# Hoslem test for stepwise selection
```{r }
hoslem.test(step.model$y, fitted(step.model), g=10)
```

# VIF and odd ratio for stepwise selection
```{r }
exp(cbind("Odds ratio" = coef(step.model), confint.default(step.model, level = 0.95)))
vif(step.model)
```


# Prediction with the stepwise  selection after taking care of the high vif

```{r }
logr<- glm(y ~ job + education + default + contact +duration + poutcome + pdays + campaign, family = binomial(link = "logit"),data = balanced_train)

# 1 way
logr.probs<-predict(logr, newdata=balanced_test)
logr.pred<-rep("No",928)
logr.pred[logr.probs>.5]="Yes"
Truth<-balanced_test[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=balanced_test)
accuracy <- table(pred, balanced_test[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```

# ROC curve for the stepwise model

```{r }
logr<-glm(y ~ job + education + default + contact +duration + poutcome + pdays + campaign, family = binomial(link = "logit"),data = balanced_train)
logr.probs<-predict(logr, newdata=balanced_test)
ME<-c()
FP<-c()
FN<-c()
index<-0:928/928
for (i in 1:928){
logr.pred<-rep("no",928)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-balanced_test[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME[i]<-(x[1,2]+x[2,1])/sum(x)
FP[i]<-x[2,1]/(x[2,1]+x[1,1])
FN[i]<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
ord.ind<-order(FP,decreasing=F)
plot(FP[ord.ind],TP[ord.ind],type="l",col="blue",ylab="True Positive Rate",xlab="False Positive Rate")
lines(0.60:0.75,0.08:0.16,lty=4,col="black",lwd=1)

simple_auc <- function(TPR, FPR){
  # inputs already sorted, best scores first 
  dFPR <- c(diff(FPR), 0)
  dTPR <- c(diff(TPR), 0)
  sum(TPR * dFPR) + sum(dTPR * dFPR)/2
}

paste("AUC=", simple_auc(TP[ord.ind],FP[ord.ind]),sep=" ")

```


# Backward selection
```{r }
model.null<-glm(y ~ ., data=balanced_train,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.main),
     direction="backward",
     test="Chisq",
     data=balanced_train)
```

# Backward final model
```{r }
backward<- glm(formula = y ~ job + education + default + contact + month + 
    duration + campaign + pdays + poutcome + emp.var.rate + cons.price.idx + 
    euribor3m + nr.employed, family = binomial(link = "logit"), 
    data = balanced_train)
backward
```

# VIF and odd ratio for backward selection
```{r }
summary(backward)
exp(cbind("Odds ratio" = coef(forward), confint.default(backward, level = 0.95)))
vif(backward)
```

# After take of the high vif for backward selection

```{r }
backwardfinal<- glm(formula = y ~ job + education + default + contact +duration + previous + pdays + campaign, family = binomial(link = "logit"),data = balanced_train)
backwardfinal
```

```{r }
summary(backwardfinal)
exp(cbind("Odds ratio" = coef(forward), confint.default(backward, level = 0.95)))
vif(backwardfinal)
```


```{r }
summary(backwardfinal)
```

```{r }
plot(backwardfinal)
```


# Prediction with the backward selection

```{r }
logr<- glm(y ~ job + education + default + contact +duration + previous + pdays + campaign, family = binomial(link = "logit"),data = balanced_train)

# 1 way
logr.probs<-predict(logr, newdata=balanced_test)
logr.pred<-rep("No",928)
logr.pred[logr.probs>.5]="Yes"
Truth<-balanced_test[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=balanced_test)
accuracy <- table(pred, balanced_test[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```


# Backward Hoslem test
```{r }
hoslem.test(backwardfinal$y, fitted(backwardfinal), g=10)
```
# ROC curve for the backward model

```{r }
logr<-glm(y ~ job + education + default + contact +duration + previous + pdays + campaign, family = binomial(link = "logit"),data = balanced_train)
logr.probs<-predict(logr, newdata=balanced_test)
ME<-c()
FP<-c()
FN<-c()
index<-0:928/928
for (i in 1:928){
logr.pred<-rep("no",928)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-balanced_test[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME[i]<-(x[1,2]+x[2,1])/sum(x)
FP[i]<-x[2,1]/(x[2,1]+x[1,1])
FN[i]<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
ord.ind<-order(FP,decreasing=F)
plot(FP[ord.ind],TP[ord.ind],type="l",col="blue",ylab="True Positive Rate",xlab="False Positive Rate")
lines(0.60:0.75,0.08:0.16,lty=4,col="black",lwd=1)

simple_auc <- function(TPR, FPR){
  # inputs already sorted, best scores first 
  dFPR <- c(diff(FPR), 0)
  dTPR <- c(diff(TPR), 0)
  sum(TPR * dFPR) + sum(dTPR * dFPR)/2
}

paste("AUC=", simple_auc(TP[ord.ind],FP[ord.ind]),sep=" ")

```
# Lasso Feature selection
```{r }
dat.train.x <- model.matrix(y~ .,balanced_train)
dat.train.y<-balanced_train[,21]
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
#CV misclassification error rate 
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#Optimal penalty
cvfit$lambda.min

```

# Prediction
```{r }
# Final
dat.test.y<- balanced_test[,21]
dat.test.y<-ifelse(dat.test.y == "yes", 1,0)
dat.test.x<- model.matrix(y~ .,balanced_test)
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)

pred <- predict(finalmodel, s = cvfit$lambda.min, newx = dat.test.x)
Mypred<-ifelse(pred>.5, 1,0)

final <- cbind(dat.test.y, Mypred)
testMSE_LASSO<-mean((dat.test.y-Mypred)^2)
testMSE_LASSO

# Checking the first six obs
head(final)

# RSQ
actual <- dat.test.y
preds <- pred
rss <- sum((preds - actual) ^ 2)
tss <- sum((actual - mean(actual)) ^ 2)
rsq <- 1 - rss/tss
rsq

```


# ROC for the lasso selection model

```{r }
pred <- predict(finalmodel, s = cvfit$lambda.min, newx = dat.test.x)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot ROC
plot(roc.perf,main="LASSO")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
```



```{r }

```



```{r }

```


# Extra code to use if we need later
```{r }
#eval_results(y_train, predictions_train, balanced_train)
#predictions_test <- predict(finalmodel, s = cvfit$lambda.min, newx = dat.test.x)
#eval_results(dat.test.y, predictions_test, balanced_test)
#fit.pred <- predict(finalmodel, newy = dat.test, type = "response")
```
