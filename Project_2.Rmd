---
title: "Project_2"
author: "Fabio_Savorgnan"
date: "3/14/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)
```


```{r }
library(dplyr)
library(ggplot2)
library(tidyr)
library(SDMTools)
library(readr)
library(digest)
library(ISLR)
library(car) 
library(leaps)
library( Matrix)
library(foreach)
library(glmnet)
library(gridExtra)
library(lsmeans)
library(limma)
library(Sleuth3)
library(tseries)
library(forecast)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(epitools)
library(samplesizeCMH)
library(caret)
library(GGally)
library(glmnet)
library(bestglm)
library(data.table)
library(broom)
library(plyr)
library(repr)
library(ResourceSelection)
library(ROCR)
library(pROC)
```

# Loading the data
```{r }
bank_20 = read.csv("bank-additional-full.csv", sep=";")
head(bank_20)
```


```{r }
summary(bank_20)
```


# Does not look like any NAs in either data set
```{r }
#Does not look like any NAs in either data set
sapply(bank_20, function(x) sum(is.na(x)))
```

#pdays- about 40k of the 41k are at level 999, no previous contact 
#could bin this data 
```{r }
hist(bank_20$pdays)
temp = bank_20 %>% filter(pdays != 999)
dim(temp)
hist(temp$pdays)
```


```{r }
#temp = bank_20 %>% filter(pdays != 999)
#dim(temp)
#hist(temp$pdays)
#summary(temp$pdays)
#within 5 days, 10 , 15, 30 and never
#clean_bank_20$newpdays = case_when(bank_20$pdays == 999 ~ "Never",
                     #bank_20$pdays >= 15 ~ "Within 30 Days", 
                     #bank_20$pdays >= 10 & bank_20$pdays < 15 ~ "Within 15 Days",
                     #bank_20$pdays >= 5 & bank_20$pdays < 10 ~ "Within 10 Days",
                     #bank_20$pdays < 5 ~ "Within 5 Days") 
#clean_bank_20 = dplyr::select(clean_bank_20, -pdays) 
```


# Reshape for a balance data
```{r }
clean_bank_20<-bank_20
yes_indices = which(clean_bank_20$y == "yes")
yes_train_indices = sample(yes_indices, length(yes_indices) * .9)
no_indices = which(clean_bank_20$y == "no")
no_train_indices = sample(no_indices, length(yes_indices))
train_indices = c(no_train_indices,yes_train_indices)

balanced_train_bank_20 = clean_bank_20[train_indices,]
balanced_train_bank_20<-balanced_train_bank_20
head(balanced_train_bank_20)
test_bank_20 = clean_bank_20[-train_indices,]
test_bank_20<-test_bank_20
head(test_bank_20)

```




# Plot EDA in general for continuous variables
```{r }
boxplot(bank_20$age~bank_20$y,xlab="Loan",ylab="Age",title="Credict Assessment",col=c("lightblue","orange"))

p1= bank_20 %>% ggplot(aes(x = duration,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Duration", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p4= p3 + scale_x_continuous(limits = c(0, 2500))
p4

boxplot(bank_20$campaign~bank_20$y,xlab="Loan",ylab="Campaign",title="Credict Assessment",col=c("lightblue","orange"))

boxplot(bank_20$previous~bank_20$y,xlab="Loan",ylab="Previous",title="Credict Assessment",col=c("lightblue","orange"))

p1= bank_20 %>% ggplot(aes(x = emp.var.rate,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Emp Var Rate", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p4= p3 + scale_x_continuous(limits = c(-3.5, 1.4))
p4
p1= bank_20 %>% ggplot(aes(x = cons.price.idx,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Cons Price Idx", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

p1= bank_20 %>% ggplot(aes(x = cons.conf.idx,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Cons Conf", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

plot(euribor3m~y,data=bank_20, main="Credict Assessment",
   xlab="Loan", ylab="euribor3m")

p1= bank_20 %>% ggplot(aes(x = nr.employed,  y = y , fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Nr Employed", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) )
p3

```
# EDA for categorical values with proportion table

```{r }
attach(bank_20)
ftable(addmargins(table(bank_20$y,bank_20$job))) 
job=factor(job)
ftable(addmargins(table(y, marital)))
marital=factor(marital)
ftable(addmargins(table(y,education)))
education=factor(education)
ftable(addmargins(table(y,default)))
education=factor(default)
ftable(addmargins(table(y,housing))) 
job=factor(housing)
ftable(addmargins(table(y, loan)))
marital=factor(loan)
ftable(addmargins(table(y,contact)))
education=factor(contact)
ftable(addmargins(table(y,month)))
education=factor(month)
ftable(addmargins(table(y,day_of_week)))
education=factor(day_of_week)
ftable(addmargins(table(y,poutcome)))
education=factor(poutcome)

#to get proportions that make sense
prop.table(table(bank_20$y,bank_20$job),2)
prop.table(table(y,education),2)
prop.table(table(y,default),2)
prop.table(table(y,housing),2)
prop.table(table(y,loan),2)
prop.table(table(y,contact),2)
prop.table(table(y,month),2)
prop.table(table(y,day_of_week),2)
prop.table(table(y,poutcome),2)

#Visualize
p1= bank_20 %>% ggplot(aes(x = job,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Job", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = education,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Education", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = default,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Default", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = marital,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Marital", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = housing,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Housing", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = loan,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Loan", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = contact,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Contact", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = month,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Month", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = day_of_week,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Day of week", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
p1= bank_20 %>% ggplot(aes(x = poutcome,  y = y, fill = y)) 
p2= p1+ geom_col() + labs(title = "Credict Approval", x= "Poutcome", y= "Aproved loan") 
p3= p2+ theme( axis.text = element_text(size = rel(0.8),angle =45, hjust = 1, vjust = 1) ) 
p3
```


# Assessing interaction
```{r }
#Interactions on Categorical Variables
#Job and Marital interaction 
clean_bank_20 %>% ggplot(aes(x = job, fill = marital))  + geom_bar(position = "fill")
#Continuous + Categorical
clean_bank_20 %>% ggplot(aes(x = job, y = nr.employed, fill = y)) + geom_boxplot()
clean_bank_20 %>% ggplot(aes(x = job, y = cons.conf.idx, fill = y)) + geom_boxplot()
clean_bank_20 %>% ggplot(aes(x = month, y = cons.conf.idx, fill = y)) + geom_boxplot()
clean_bank_20 %>% ggplot(aes(x = month, y = log(duration), fill = y)) + geom_boxplot()
#Continuous + Continous
clean_bank_20 %>% ggplot(aes(x = euribor3m, y = cons.conf.idx, color = y)) + geom_jitter()
```



#PCA for continuous variables
```{r }
pc.bc<-prcomp(bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)],scale.=TRUE)
pc.bc.scores<-pc.bc$x
#Adding the response column to the PC's data frame
pc.bc.scores<-data.frame(pc.bc.scores)
pc.bc.scores$loan<-bank_20$y

#Use ggplot2 to plot the first few pc's
library(ggplot2)
ggplot(data = pc.bc.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col= loan), size=1)+
  ggtitle("PCA of Credict Assessment")
```

# Heat map for continuous variables
```{r }
my.cor<-cor(bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)])
my.cor
library(gplots)
library(ggplot2)
heatmap.2(my.cor,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("row"), 
          symm=F,symkey=T,symbreaks=T, scale="none")
```


# Pair correlation numerical variables
```{r }
# Prepare some data
df <- bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
# Correlation plot
ggcorr(df, palette = "RdBu", label = TRUE)
```


# Running LDA
```{r }
# Build X_train, y_train, X_test, y_test
X_train <- balanced_train_bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_train<-balanced_train_bank_20[,21]

X_test <- test_bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_test <- test_bank_20[,21]
mylda<-lda(y ~ age + duration + campaign+pdays + previous + emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed, data= balanced_train_bank_20)
pred<-predict(mylda,newdata=X_test )$class  
Truth<-y_test
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/114
FP<-x[2,1]/(x[2,1]+x[1,1])
FN<-x[1,2]/(x[1,2]+x[2,2])
TP= 1-FN
TP
ME
FP
FN
#Calculating overall accuracy
oneminusME<-1-ME
oneminusME
```


# ROC for the LDA model
```{r }
X_train <- balanced_train_bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_train<-balanced_train_bank_20[,21]
y_train <- as.factor(as.character(y_train))
X_test <- test_bank_20[,-c(2,3,4,5,6,7,8,9,10,15,21)]
y_test <- test_bank_20[,21]
y_test <- as.factor(as.character(y_test))
mylda<-lda(y ~ age + duration + campaign+pdays + previous + emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed, data= balanced_train_bank_20)
pred.lda<-predict(mylda,newdata=X_test )
predsld <- pred.lda$posterior
predsld <- as.data.frame(predsld)
predsld <- prediction(predsld[,1],y_test)
roc.perfld = performance(predsld, measure = "tpr", x.measure = "fpr")
auc.trainld <- performance(predsld, measure = "auc")
auc.trainld <- auc.trainld@y.values
plot(roc.perfld)
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc.trainld[[1]],3), sep = ""))
```



# Selection of the variable for LLR 

# Forward

```{r }
model.main<- glm(y~ ., balanced_train_bank_20,family = binomial(link="logit"))
model.null<-glm(y ~ 1, data=balanced_train_bank_20,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.main),
     direction="forward",
     test="Chisq",
     data=balanced_train)
```


# The forward selection select a lot of variables. Please see below.
```{r }
forward<- glm(formula = y ~ duration + nr.employed + month + poutcome + 
    emp.var.rate + cons.price.idx + job + euribor3m + contact + 
    day_of_week + pdays + default + previous, family = binomial(link = "logit"), 
    data = balanced_train_bank_20)
forward
```


# Forward Odd ratio
```{r }
exp(cbind("Odds ratio" = coef(forward), confint.default(forward, level = 0.95)))
vif(forward)
```

# Take off the high VIF variances 
```{r }
forward2<- glm(formula = y ~ duration + job + contact + day_of_week + default + previous+ pdays, family = binomial(link = "logit"), data = balanced_train_bank_20)
forward2
```


# Plot forward

```{r }
plot(forward2)
```


# Summary model forward

```{r }
summary(forward2)
```

# Prediction with the forward selection

```{r }
logr<-glm(y ~ duration + job + contact + day_of_week + default + previous+ pdays, family = binomial(link = "logit"), data =  balanced_train_bank_20)

# 1 way
logr.probs<-predict(logr, newdata=test_bank_20)
logr.pred<-rep("No",32372)
logr.pred[logr.probs>.5]="Yes"
Truth<-test_bank_20[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=test_bank_20)
accuracy <- table(pred, test_bank_20[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```

# Holmes test for forward selecttion
```{r }
hoslem.test(forward$y, fitted(forward), g=10)

```

# Sens/spec for forward model

```{r }
logr<-glm(formula = y ~ duration + job + contact + day_of_week + default + previous+ pdays, family = binomial(link = "logit"), data = balanced_train_bank_20)
logr.probs<-predict(logr, newdata=test_bank_20)
ME<-c()
FP<-c()
FN<-c()
index<-0:32372/32372
for (i in 1:32372){
logr.pred<-rep("no",32372)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-test_bank_20[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME<-(x[1,2]+x[2,1])/sum(x)
FP<-x[2,1]/(x[2,1]+x[1,1])
FN<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
TP
ME
FP
FN
```

# ROC curve for the forward model
```{r }
dat.train.x <- as.data.frame(balanced_train_bank_20)
dat.train.y <- balanced_train_bank_20$y
dat.train.y <- as.factor(as.character(dat.train.y))
dat.test.x<-as.data.frame(test_bank_20)
dat.test.y<- test_bank_20$y
dat.test.y <- as.factor(as.character(dat.test.y))

logr1<-glm(formula = y ~ duration + job + contact + day_of_week + default + previous+ pdays, family = binomial(link = "logit"), data = balanced_train_bank_20)
logr.probs1<-predict(logr1, newdata=dat.test.x)

#Compare the prediction to the real outcome
head(logr.probs1)
head(dat.train.y)

#Create ROC curves
pred1 <- prediction(logr.probs1, dat.test.y)
roc.perf1 = performance(pred1, measure = "tpr", x.measure = "fpr")
auc.train1 <- performance(pred1, measure = "auc")
auc.train1 <- auc.train1@y.values

#Plot ROC
plot(roc.perf1)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train1[[1]],3), sep = ""))

```




# Stepwise selection 
```{r }
full.model <- glm(y ~., data = balanced_train_bank_20, family = binomial)
coef(full.model)
step.model <- full.model %>% stepAIC(trace = FALSE)
coef(step.model)
# Make predictions
probabilities <- full.model %>% predict(test_bank_20, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "yes", "no")
# Prediction accuracy
observed.classes <- test_bank_20$y
mean(predicted.classes == observed.classes)
# Make predictions
probabilities <- predict(step.model, test_bank_20, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "yes", "no")
# Prediction accuracy
observed.classes <- test_bank_20$y
mean(predicted.classes == observed.classes)

```

# Summary for the stepwise model
```{r }
summary(step.model)
```

# Plot the stepwise model
```{r }
plot(step.model)
```


# Hoslem test for stepwise selection
```{r }
hoslem.test(step.model$y, fitted(step.model), g=10)
```

# VIF and odd ratio for stepwise selection
```{r }
exp(cbind("Odds ratio" = coef(step.model), confint.default(step.model, level = 0.95)))
vif(step.model)
```


# Prediction with the stepwise  selection after taking care of the high vif

```{r }
logr<- glm(y ~ job + education + default + contact +duration + poutcome + campaign + month + previous, family = binomial(link = "logit"),data = balanced_train_bank_20)

# 1 way
logr.probs<-predict(logr, newdata=test_bank_20)
logr.pred<-rep("No",32372)
logr.pred[logr.probs>.5]="Yes"
Truth<-test_bank_20[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=test_bank_20)
accuracy <- table(pred, test_bank_20[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```

# Sens/spec for stepwise model

```{r }
logr<-glm(y ~ job + education + default + contact +duration + poutcome + pdays + campaign, family = binomial(link = "logit"),data = balanced_train_bank_20)
logr.probs<-predict(logr, newdata=test_bank_20)
ME<-c()
FP<-c()
FN<-c()
index<-0:32372/32372
for (i in 1:32372){
logr.pred<-rep("no",32372)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-test_bank_20[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME<-(x[1,2]+x[2,1])/sum(x)
FP<-x[2,1]/(x[2,1]+x[1,1])
FN<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
TP
ME
FP
FN

```


# ROC curve for the stepwise model
```{r }
dat.train.x <- as.data.frame(balanced_train_bank_20)
dat.train.y <- balanced_train_bank_20$y
dat.train.y <- as.factor(as.character(dat.train.y))
dat.test.x<-as.data.frame(test_bank_20)
dat.test.y<- test_bank_20$y
dat.test.y <- as.factor(as.character(dat.test.y))

logr2<-glm(y ~ job + education + default + contact +duration + poutcome + pdays + campaign, family = binomial(link = "logit"),data = balanced_train_bank_20)
logr.probs2<-predict(logr2, newdata=dat.test.x)

#Compare the prediction to the real outcome
head(logr.probs2)
head(dat.train.y)

#Create ROC curves
pred2 <- prediction(logr.probs2, dat.test.y)
roc.perf2 = performance(pred2, measure = "tpr", x.measure = "fpr")
auc.train2 <- performance(pred2, measure = "auc")
auc.train2 <- auc.train2@y.values

#Plot ROC
plot(roc.perf2)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train2[[1]],3), sep = ""))

```

# Backward selection
```{r }
model.null<-glm(y ~ ., data=balanced_train_bank_20,family = binomial(link="logit"))
step(model.null,
     scope = list(upper=model.main),
     direction="backward",
     test="Chisq",
     data=balanced_train)
```

# Backward final model
```{r }
backward<- glm(formula = y ~ job + education + default + contact + month + 
    duration + campaign + pdays + poutcome + emp.var.rate + cons.price.idx + 
    euribor3m + nr.employed, family = binomial(link = "logit"), 
    data =balanced_train_bank_20 )
backward
```

# VIF and odd ratio for backward selection
```{r }
exp(cbind("Odds ratio" = coef(forward), confint.default(backward, level = 0.95)))
vif(backward)
```

# After take of the high vif for backward selection

```{r }
backwardfinal<- glm(formula = y ~ job + education + default + contact +duration + pdays + campaign + month, family = binomial(link = "logit"),data = balanced_bank_20)
backwardfinal
```
# VIF and odd ratio for backward model
```{r }
exp(cbind("Odds ratio" = coef(forward), confint.default(backward, level = 0.95)))
vif(backwardfinal)
```

# Summary for backward model
```{r }
summary(backwardfinal)
```
# Plot backward model
```{r }
plot(backwardfinal)
```


# Prediction with the backward selection

```{r }
logr<- glm(y ~ job + education + default + contact +duration + previous + pdays + campaign, family = binomial(link = "logit"),data = balanced_train_bank_20)

# 1 way
logr.probs<-predict(logr, newdata=test_bank_20)
logr.pred<-rep("No",32372)
logr.pred[logr.probs>.5]="Yes"
Truth<-test_bank_20[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=test_bank_20)
accuracy <- table(pred, test_bank_20[,21])
sum(diag(accuracy))/sum(accuracy)
#confusionMatrix(factor(pred, levels = 1:928), factor(balanced_test$y, levels = 1:928))

```


# Backward Hoslem test
```{r }
hoslem.test(backwardfinal$y, fitted(backwardfinal), g=10)
```
# Sens/spec for backward model

```{r }
logr<-glm(y ~ job + education + default + contact +duration + pdays + campaign + poutcome, family = binomial(link = "logit"),data = balanced_train_bank_20)
logr.probs<-predict(logr, newdata=test_bank_20)
ME<-c()
FP<-c()
FN<-c()
index<-0:32372/32372
for (i in 1:32372){
logr.pred<-rep("no",32372)
logr.pred[logr.probs>index[i]]="yes"
logr.pred<-factor(logr.pred,levels=c("no","yes"))
Truth<-test_bank_20[,21]
Pred<-logr.pred
x<-table(Pred,Truth)
ME<-(x[1,2]+x[2,1])/sum(x)
FP<-x[2,1]/(x[2,1]+x[1,1])
FN<-x[1,2]/(x[1,2]+x[2,2])
}
TP= 1-FN
TP
ME
FP
FN

```

# ROC curve for the backward model
```{r }
dat.train.x <- as.data.frame(balanced_train_bank_20)
dat.train.y <- balanced_train_bank_20$y
dat.train.y <- as.factor(as.character(dat.train.y))
dat.test.x<-as.data.frame(test_bank_20)
dat.test.y<- test_bank_20$y
dat.test.y <- as.factor(as.character(dat.test.y))

logr3<- glm(y ~ job + education + default + contact +duration + pdays + campaign + poutcome, family = binomial(link = "logit"),data = balanced_train_bank_20)
logr.probs3<-predict(logr3, newdata=test_bank_20)

#Compare the prediction to the real outcome
head(logr.probs3)
head(dat.train.y)

#Create ROC curves
pred3 <- prediction(logr.probs3, dat.test.y)
roc.perf3 = performance(pred3, measure = "tpr", x.measure = "fpr")
auc.train3 <- performance(pred3, measure = "auc")
auc.train3 <- auc.train3@y.values

#Plot ROC
plot(roc.perf1)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train3[[1]],3), sep = ""))

```


# Lasso Feature selection
```{r }
dat.train.x <- model.matrix(y~ .,balanced_train_bank_20)
dat.train.y<-balanced_train_bank_20[,21]
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
#CV misclassification error rate 
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#Optimal penalty
cvfit$lambda.min

```

# Prediction
```{r }
# Final
dat.test.y<- test_bank_20[,21]
dat.test.y<-ifelse(dat.test.y == "yes", 1,0)
dat.test.x<- model.matrix(y~ .,test_bank_20)
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)

pred <- predict(finalmodel, s = cvfit$lambda.min, newx = dat.test.x)
Mypred<-ifelse(pred>.5, 1,0)

final <- cbind(dat.test.y, Mypred)
testMSE_LASSO<-mean((dat.test.y-Mypred)^2)
testMSE_LASSO

# Checking the first six obs
head(final)

# RSQ
actual <- dat.test.y
preds <- pred
rss <- sum((preds - actual) ^ 2)
tss <- sum((actual - mean(actual)) ^ 2)
rsq <- 1 - rss/tss
rsq

```


# Confusion matrix
```{r }
logr.pred<-pred
logr.pred<-rep("No", 32372)
logr.pred[logr.probs>.5]="Yes"
Truth<-test_bank_20[,21]
Pred<-logr.pred
ftable(addmargins(table(Pred,Truth)))

# 2 way
pred = predict(logr, newdata=test_bank_20)
accuracy <- table(pred, test_bank_20[,21])
sum(diag(accuracy))/sum(accuracy)
```

# Sens/spec for lasso model

```{r }
logr.pred<-pred
logr.pred<-rep("No",32372)
logr.pred[logr.probs>.5]="Yes"
Truth<-test_bank_20[,21]
Pred<-logr.pred
x<- ftable(addmargins(table(Pred,Truth)))

ME<-(x[1,2]+x[2,1])/sum(x)
FP<-x[2,1]/(x[2,1]+x[1,1])
FN<-x[1,2]/(x[1,2]+x[2,2])
TP= 1-FN
TP
ME
FP
FN
```



# ROC for the lasso selection model

```{r }
# Predict from model
preds <- predict(finalmodel, newx = dat.test.x, type = 'response')

# Calculate true positive rate and false positive rate on the prediction object
perf <- performance(prediction(preds, dat.test.y), 'tpr', 'fpr')

auc.train <- performance(prediction(preds, dat.test.y), measure = "auc")
auc.train <- auc.train@y.values

#Plot ROC
plot(perf,main="LASSO")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

```


# Jusnt another way of doing
```{r }
pred <- predict(finalmodel, s = cvfit$lambda.min, newx = dat.test.x)
roc.perfl = performance(prediction(pred, dat.test.y), 'tpr', 'fpr')
auc.train <- performance(prediction(pred, dat.test.y), measure = 'auc')
auc.train <- auc.train@y.values
#Plot ROC
plot(roc.perfl,main="LASSO")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
```



# Compare ROC from differents model
```{r }
plot( roc.perf1, colorize = TRUE)
plot(roc.perf2, add = TRUE, colorize = TRUE)
plot(roc.perf3, add = TRUE, colorize = TRUE)
plot(roc.perfl, add = TRUE, colorize = TRUE)
abline(a=0, b= 1)

#without color for cutoff; but adding colors to allow for comarisons of the curves
plot( roc.perf1, col="black", add = TRUE)
plot(roc.perf2,col="orange", add = TRUE)
plot(roc.perf3,col="blue", add = TRUE)
plot(roc.perfl,col="yellow", add = TRUE)
legend("bottomright",legend=c("Forward","Stepwise","Backward", "Lasso"),col=c("black","orange","blue","yellow"),lty=1,lwd=1)
abline(a=0, b= 1)
```



```{r }

```



